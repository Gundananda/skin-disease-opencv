```python
# Write and render README.md for the Face Skin Disease Detection project (no images)
from IPython.display import Markdown, display

readme = r"""
# ğŸ‘©â€âš•ï¸ Face Skin Disease Detection with Attention Fusion (TensorFlow/Keras)

<div align="center">

[![Python](https://img.shields.io/badge/Python-3.9%2B-blue?logo=python&logoColor=white)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.9%2B-FF6F00?logo=tensorflow&logoColor=white)](https://www.tensorflow.org/)
[![Keras](https://img.shields.io/badge/Keras-2.9%2B-D00000?logo=keras&logoColor=white)](https://keras.io/)
[![OpenCV](https://img.shields.io/badge/OpenCV-4.x-5C3EE8?logo=opencv&logoColor=white)](https://opencv.org/)
[![Albumentations](https://img.shields.io/badge/Albumentations-1.x-00A896)](https://albumentations.ai/)
[![License](https://img.shields.io/badge/License-MIT-green)](LICENSE)

Endâ€‘toâ€‘end pipeline to detect common face skin conditions from selfie video using dual backbones (ResNet101 + DenseNet121) with attention fusion, skin segmentation, and majorityâ€‘vote inference.

</div>

---

## ğŸ“Œ Overview

This project provides:
- A training notebook to build an attentionâ€‘fused model on curated faceâ€‘skin datasets.
- An inference notebook that records a 5â€‘second selfie video, extracts frames, performs skin detection, predicts perâ€‘frame, and uses majority voting for a final label.

> âš ï¸ Medical disclaimer: This project is for research/education only and is not a medical device. Do not use it for diagnosis or treatment. Consult qualified healthcare professionals for medical advice.

---

## âœ¨ Key Features

| Feature | Description |
| :--- | :--- |
| ğŸ§  Attention Fusion | Dual ImageNet backbones (ResNet101 + DenseNet121) fused via learnable soft attention (2â€‘way weights). |
| ğŸ¥ Video â†’ Frames | Record 5s selfie (OpenCV), extract frames for robust voting. |
| ğŸ¯ Skin Segmentation | HSVâ€‘based skin mask to focus the model on skin regions. |
| ğŸ§ª Strong Augmentations | Albumentations pipeline; classes balanced to a target count (e.g., 500/class). |
| ğŸ§° Transfer Learning | Pretrained weights; GAP + Dense layers with BN/Dropout. |
| ğŸ—³ï¸ Majority Voting | Stable final prediction across frames. |

---

## ğŸ“‚ Project Structure

```plaintext
face-skin-disease/
â”œâ”€â”€ Face disease detection final.ipynb   # Inference pipeline (video â†’ frames â†’ skin â†’ predict â†’ vote)
â”œâ”€â”€ skin disease attention.ipynb         # Training pipeline (data prep, augment, train, eval)
â”œâ”€â”€ skin_disease.h5                      # Trained model weights (not in repo)
â”œâ”€â”€ frames/                              # Extracted frames (generated)
â”œâ”€â”€ processed_skin_frames/               # Skin-masked frames (generated)
â”œâ”€â”€ balanced_train_df.csv                # Saved balanced metadata (generated during training)
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```

---

## ğŸ“¦ Datasets

- Face Skin Disease dataset (Kaggle) paths used in training:
  - Train: `/kaggle/input/face-skin-disease/DATA/train`
  - Test: `/kaggle/input/face-skin-disease/DATA/testing`
- Additional â€œnormalâ€ class images sourced from:
  - `/kaggle/input/selfies-id-images-dataset/Selfies ID Images dataset`
  - 236 normal images sampled and added.
- Label harmonization:
  - Ensure consistent class names. If any label appears as `Eczemaa`, map it to `Eczema`.
- Final class set (6):
  - `['normal', 'Eczema', 'Acne', 'Rosacea', 'Actinic Keratosis', 'Basal Cell Carcinoma']`

Note: Datasets are large and not included in the repo. Update paths as needed.

---

## ğŸ§  Model Architecture (Training)

- Backbones: ResNet101 + DenseNet121 (include_top=False, ImageNet weights)
- Heads: GAP â†’ Dense(512) â†’ BN â†’ Dense(256) â†’ BN â†’ Dropout(0.3) â†’ Dense(128)
- Attention fusion:
  - Concatenate(128+128) â†’ Dense(2, softmax) â†’ weights [Î±_resnet, Î±_densenet]
  - Multiply each branch by its weight, then Add
- Classifier:
  - Dense(256) â†’ BN â†’ Dropout(0.3) â†’ Dense(128) â†’ BN â†’ Dropout(0.3) â†’ Dense(6, softmax)
- Training:
  - Optimizer: Adam(lr=1e-4)
  - Loss: sparse_categorical_crossentropy
  - Input size: 224Ã—224, batch size: 16
  - Augmentation: Albumentations; classes balanced to target_count=500

Results (your run):
- Validation Accuracy: ~0.8500
- Test Accuracy: ~0.8475

---

## ğŸ›ï¸ Inference Pipeline (Notebook: Face disease detection final.ipynb)

1) Record selfie video (5 seconds, 20 FPS) with OpenCV â†’ `selfie_video.avi`
2) Extract frames â†’ `frames/`
3) Skin detection (HSV range: lower=(0,48,80), upper=(20,255,255)) â†’ `processed_skin_frames/`
4) Load trained model weights `skin_disease.h5`
5) Predict per frame (224Ã—224, scaled 0â€“1), map to class names
6) Majority vote across frames â†’ Final predicted condition

Tip: Ensure `class_names` matches the order the model was trained on.

---

## ğŸš€ Getting Started

### Prerequisites
- Python 3.9+
- GPU recommended for training

### Installation
```bash
pip install tensorflow keras opencv-python albumentations pandas numpy scikit-learn pillow tqdm
```

### Train (optional)
- Open `skin disease attention.ipynb`
- Set dataset paths
- Run cells to:
  - Build `train_df`, add 236 â€œnormalâ€ images, balance to ~500/class with Albumentations
  - Split into train/val
  - Train attentionâ€‘fusion model
  - Save weights to `skin_disease.h5`

### Inference
- Place `skin_disease.h5` alongside `Face disease detection final.ipynb`
- Run the notebook cells in order
- Final console output shows majorityâ€‘vote prediction

---

## âš–ï¸ Limitations

- Not a diagnostic tool; class labels may be visually similar.
- Dataset domain shift (lighting, camera, ethnicity, makeup, artifacts) can degrade accuracy.
- HSV skin masking is heuristic; may exclude/inflate regions in varied lighting.
- Majority voting helps stability but cannot correct systematic bias.

---

## ğŸ”’ Privacy & Safety

- Obtain explicit consent for recording.
- Prefer local execution; avoid uploading selfies to external servers.
- Anonymize and securely delete data after use.

---

## ğŸ§ª Reproducibility

- Fix seeds where possible; document data versions.
- Save label encoder and class index mapping used at train time.
- Keep the exact preprocessing consistent between train and inference.

---

## ğŸ“„ License

Released under the MIT License. See `LICENSE`.

---

## ğŸ‘¨â€ğŸ’» Authors

- Your Name â€” add GitHub/LinkedIn links
- Contributors welcome! Open an issue or PR.

---

â­ï¸ If this repo helps your work, consider giving it a star!
"""

with open("README.md", "w", encoding="utf-8") as f:
    f.write(readme.strip() + "\n")

display(Markdown(readme))
print("README.md written.")
```
